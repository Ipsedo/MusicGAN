{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_block = nn.Sequential(\n",
    "    nn.ConvTranspose2d(\n",
    "        32, 32,\n",
    "        kernel_size=(3, 3),\n",
    "        stride=(2, 2),\n",
    "        padding=(1, 1),\n",
    "        output_padding=(1, 1)\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.ConvTranspose2d(\n",
    "        32, 24,\n",
    "        kernel_size=(3, 3),\n",
    "        stride=(1, 1),\n",
    "        padding=(1, 1)\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.ConvTranspose2d(\n",
    "        24, 1,\n",
    "        kernel_size=(1, 1),\n",
    "        stride=(1, 1),\n",
    "        padding=(0, 0)\n",
    "    ),\n",
    "    nn.Tanh()\n",
    ")\n",
    "\n",
    "last_block = nn.Sequential(\n",
    "    nn.ConvTranspose2d(\n",
    "        32, 1,\n",
    "        kernel_size=(1, 1),\n",
    "        stride=(1, 1),\n",
    "        padding=(0, 0)\n",
    "    ),\n",
    "    nn.Tanh(),\n",
    "    nn.Upsample(\n",
    "        scale_factor=2,\n",
    "        mode=\"nearest\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_block[0].weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_block[0].weight[:, :, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with th.no_grad():\n",
    "    new_block[0].weight.zero_()\n",
    "    new_block[0].weight[:, :, 1, 1] = th.eye(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_block[0].weight[:, :, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "last_block[0].weight[:, :, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code Thierry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun May 15 14:11:27 2022\n",
    "\n",
    "@author: thierry\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def multiple(A,p):\n",
    "    \n",
    "    n,q = A.shape\n",
    "    if min(n,q)>p:\n",
    "        print('On fait une ACP...')\n",
    "        \n",
    "    U,D,V = np.linalg.svd(A, full_matrices=True)\n",
    "\n",
    "    DD = np.zeros(p)\n",
    "    DD[:min([n,p,q])] = np.sqrt(D[:min([n,p,q])])\n",
    "    D1 = np.zeros((n,p))\n",
    "    np.fill_diagonal(D1,DD)\n",
    "    D2 = np.zeros((p,q))  \n",
    "    np.fill_diagonal(D2,DD)\n",
    "    \n",
    "    G = np.random.normal(size=(p,p))\n",
    "    G = G+np.transpose(G)   \n",
    "    E,W = np.linalg.eigh(G)\n",
    "    \n",
    "    B = np.matmul(U,np.matmul(D1,W))\n",
    "    C = np.matmul(np.transpose(W),np.matmul(D2,V))    \n",
    "    \n",
    "    return(B,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_diag(m: th.Tensor, v: th.Tensor) -> th.Tensor:\n",
    "    mask = th.diag(th.ones_like(v))\n",
    "    full_mask = th.zeros(*m.size())\n",
    "    start, end = min(full_mask.size()[0], mask.size()[0]), min(full_mask.size()[1], mask.size()[1])\n",
    "    full_mask[:start, :end] = mask[:start, :end]\n",
    "    \n",
    "    diag = th.diag(v)\n",
    "    full_diag = th.zeros(*m.size())\n",
    "    start, end = min(full_diag.size()[0], diag.size()[0]), min(full_diag.size()[1], diag.size()[1])\n",
    "    full_diag[:start, :end] = diag[:start, :end]\n",
    "    \n",
    "    return full_mask * full_diag + (1. - full_mask) * m\n",
    "\n",
    "def decomposition(m: th.Tensor, p: int) -> Tuple[th.Tensor, th.Tensor]:\n",
    "    n, q = m.size()[-2:]\n",
    "    \n",
    "    u, d, v = th.linalg.svd(m, full_matrices=True)\n",
    "    \n",
    "    d_diag = th.zeros(p)\n",
    "    d_diag[:min(n, p, q)] = th.sqrt(d[:min(n, p, q)])\n",
    "    \n",
    "    d1 = th.zeros(n, p)\n",
    "    d1 = fill_diag(d1, d_diag)\n",
    "    \n",
    "    d2 = th.zeros(p, q)\n",
    "    d2 = fill_diag(d2, d_diag)\n",
    "    \n",
    "    g = th.randn(p, p)\n",
    "    g = g + g.transpose(1, 0)\n",
    "    e, w = th.linalg.eigh(g)\n",
    "    \n",
    "    b = u @ (d1 @ w)\n",
    "    c = w.transpose(1, 0) @ (d2 @ v)\n",
    "    \n",
    "    return b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = th.randn(64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1, m_2 = decomposition(m, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round(t: th.Tensor, decimals=0) -> th.Tensor:\n",
    "    return (t * 10 ** decimals).round() / (10 ** decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True, False],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(m_1 @ m_2, decimals=5) == round(m, decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu113'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.ConvTranspose2d(\n",
    "    32, 32,\n",
    "    kernel_size=(3, 3),\n",
    "    stride=(2, 2),\n",
    "    padding=(1, 1),\n",
    "    output_padding=(1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.zeros_(conv.weight)\n",
    "nn.init.zeros_(conv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight.data[:, :, 1:, 1:] = (\n",
    "    th.eye(32)[:, :, None, None]\n",
    "    .repeat(1, 1, 2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data[:, :, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = th.ones(1, 32, 2, 2)\n",
    "v[:, :, 0, 0] = 1\n",
    "v[:, :, 1, 0] = 2\n",
    "v[:, :, 0, 1] = 3\n",
    "v[:, :, 1, 1] = 4\n",
    "o = conv(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]]]], grad_fn=<SlowConvTranspose2DBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(\n",
    "    32, 32,\n",
    "    kernel_size=(3, 3),\n",
    "    stride=(2, 2),\n",
    "    padding=(1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.zeros_(conv.weight)\n",
    "nn.init.zeros_(conv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conv.weight.data[:, :, 1:, 1:] = (\n",
    "    th.eye(32)[:, :, None, None]\n",
    "    .repeat(1, 1, 2, 2) / 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "o = conv(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]]]], grad_fn=<SlowConv2DBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_gan.networks import matrix_multiple\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = th.randn(32, 2)\n",
    "b, c = matrix_multiple(a, 24)\n",
    "\n",
    "v = th.randn(4, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(v @ b @ c, decimals=5) == round(v @ a, decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InstanceNorm1d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_norm_32 = nn.InstanceNorm1d(32, affine=False).eval()\n",
    "inst_norm_24 = nn.InstanceNorm1d(24, affine=False).eval()\n",
    "inst_norm_2 = nn.InstanceNorm1d(2, affine=False).eval()\n",
    "inst_norm_2.eval()\n",
    "inst_norm_24.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 24])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(v @ b).size()\n",
    "#inst_norm_24(v @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 spatial element when training, got input size torch.Size([4, 24, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_121109/2692350351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     print(round(\n\u001b[0;32m----> 3\u001b[0;31m             inst_norm_2((inst_norm_24((v @ b).unsqueeze(-1)).squeeze(-1) @ c).unsqueeze(-1)), decimals=5) == \\\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst_norm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;32m~/PycharmProjects/MusicGAN/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/MusicGAN/venv/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         return F.instance_norm(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             self.training or not self.track_running_stats, self.momentum, self.eps)\n",
      "\u001b[0;32m~/PycharmProjects/MusicGAN/venv/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minstance_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[1;32m   2324\u001b[0m         )\n\u001b[1;32m   2325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0m_verify_spatial_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m     return torch.instance_norm(\n\u001b[1;32m   2328\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/MusicGAN/venv/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_spatial_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 spatial element when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 spatial element when training, got input size torch.Size([4, 24, 1])"
     ]
    }
   ],
   "source": [
    "with th.no_grad():\n",
    "    print(round(\n",
    "            inst_norm_2((inst_norm_24((v @ b).unsqueeze(-1)).squeeze(-1) @ c).unsqueeze(-1)), decimals=5) == \\\n",
    "        round(inst_norm_2((v @ a).unsqueeze(-1)), decimals=5)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(b @ c)[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(b @ c)[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test DecBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_gan.networks import ToMagnPhase, DecBlock, matrix_multiple\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_mp = ToMagnPhase(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_block = DecBlock(32, 24)\n",
    "new_to_mp = ToMagnPhase(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = to_mp.conv.bias.data\n",
    "m = to_mp.conv.weight.data[:, :, 0, 0]\n",
    "\n",
    "factor_1, factor_2 = matrix_multiple(m, 24)\n",
    "\n",
    "new_to_mp.from_layer(factor_2, b)\n",
    "new_block.from_layer(factor_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.randn(1, 32, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_old = to_mp(x)\n",
    "out_new = new_to_mp(new_block(x, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7da8d08070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(out_old[0, 0, :, :].detach(), cmap=\"plasma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7da8c4cd00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAIIUlEQVR4nO3dwYuc9R3H8c+nkxWlSoXuHkISowcRxIOBJYcKhQaErRd7NAdP0pyECL149R/w5mXB0BZEEeJBxCI5LEioxqwhikm0BMG6ImS3IhoKDVm+PewcUlmYx+b3zJNnP+8XDMw8GZ79/pK895l5ZnbHVSUAe9svhh4AQP8IHQhA6EAAQgcCEDoQgNCBAKMO3faK7S9sX7X94tDztGT7lO1rtj8bepY+2D5ke832ZduXbJ8ceqZWbN9t+yPbn0zX9tLgM431dXTbE0n/kPSkpA1J5yUdr6rLgw7WiO3fSrou6a9V9djQ87Rme7+k/VV1wfZ9kj6W9Ie98O9n25J+WVXXbS9IOivpZFV9ONRMYz6iH5V0taq+rKobkt6Q9PTAMzVTVe9L+m7oOfpSVd9W1YXp9R8lXZF0YNip2qgd16c3F6aXQY+oYw79gKSvb7m9oT3yHyWN7QclHZF0buBRmrE9sX1R0jVJZ6pq0LWNOXTsAbbvlXRa0gtV9cPQ87RSVdtV9bikg5KO2h706deYQ/9G0qFbbh+cbsNITJ+/npb0WlW9NfQ8faiq7yWtSVoZco4xh35e0sO2H7J9l6RnJL098EzoaHrC6lVJV6rq5aHnacn2ku37p9fv0c4J48+HnGm0oVfVTUnPS3pPOydy3qyqS8NO1Y7t1yV9IOkR2xu2nxt6psaekPSspGO2L04vTw09VCP7Ja3Z/lQ7B6QzVfXOkAON9uU1AN2N9ogOoDtCBwIQOhCA0IEAhA4EGH3otk8MPUOfWN+43SnrG33oku6Iv8gesb5xuyPWtxdCBzBDL2+Y+fXipB44vK/5fneztbmtxaXJXL7WEFjfuM17ff/86qb+tbXtn27vpcYHDu/T2t/5iVFg3n73m91/rouH7kAAQgcCEDoQgNCBAIQOBCB0IAChAwEIHQhA6EAAQgcCEDoQgNCBAIQOBCB0IAChAwEIHQhA6EAAQgcCEDoQgNCBAIQOBCB0IECn0G2v2P7C9lXbL/Y9FIC2ZoZueyLpFUm/l/SopOO2H+17MADtdDmiH5V0taq+rKobkt6Q9HS/YwFoqUvoByR9fcvtjek2ACPR7GSc7RO2122vb21ut9otgAa6hP6NpEO33D443fY/qmq1qparankvf2geMEZdQj8v6WHbD9m+S9Izkt7udywALc38NNWqumn7eUnvSZpIOlVVl3qfDEAznT42uarelfRuz7MA6AnvjAMCEDoQgNCBAIQOBCB0IAChAwEIHQhA6EAAQgcCEDoQgNCBAIQOBCB0IAChAwEIHQhA6EAAQgcCEDoQgNCBAIQOBCB0IAChAwEIHQhA6EAAQgcCEDoQgNCBAIQOBCB0IAChAwEIHQhA6EAAQgcCEDoQgNCBAIQOBCB0IAChAwEIHQhA6EAAQgcCEDoQgNCBAIQOBCB0IAChAwEIHQgwM3Tbp2xfs/3ZPAYC0F6XI/qfJa30PAeAHs0Mvarel/TdHGYB0BOeowMBmoVu+4TtddvrW5vbrXYLoIFmoVfValUtV9Xy4tKk1W4BNMBDdyBAl5fXXpf0gaRHbG/Yfq7/sQC0tG/WHarq+DwGAdAfHroDAQgdCEDoQABCBwIQOhCA0IEAhA4EIHQgAKEDAQgdCEDoQABCBwIQOhCA0IEAhA4EIHQgAKEDAQgdCEDoQABCBwIQOhCA0IEAM3/dM/Ic+tUfhx4B/6d/33hl1+0c0YEAhA4EIHQgAKEDAQgdCEDoQABCBwIQOhCA0IEAhA4EIHQgAKEDAQgdCEDoQABCBwIQOhCA0IEAhA4EIHQgAKEDAQgdCEDoQABCBwIQOhBgZui2D9les33Z9iXbJ+cxGIB2unxSy01Jf6qqC7bvk/Sx7TNVdbnn2QA0MvOIXlXfVtWF6fUfJV2RdKDvwQC087Oeo9t+UNIRSed6mQZALzqHbvteSaclvVBVP+zy5ydsr9te39rcbjkjgNvUKXTbC9qJ/LWqemu3+1TValUtV9Xy4tKk5YwAblOXs+6W9KqkK1X1cv8jAWityxH9CUnPSjpm++L08lTPcwFoaObLa1V1VpLnMAuAnvDOOCAAoQMBCB0IQOhAAEIHAhA6EIDQgQCEDgQgdCAAoQMBCB0IQOhAAEIHAhA6EIDQgQCEDgQgdCAAoQMBCB0IQOhAAEIHAhA6EIDQgQCEDgQgdCAAoQMBCB0IQOhAAEIHAhA6EIDQgQCEDgQgdCAAoQMBCB0IQOhAAEIHAhA6EIDQgQCEDgQgdCAAoQMBCB0IQOhAAEIHAhA6EIDQgQAzQ7d9t+2PbH9i+5Ltl+YxGIB29nW4z38kHauq67YXJJ21/beq+rDn2QA0MjP0qipJ16c3F6aX6nMoAG11eo5ue2L7oqRrks5U1bld7nPC9rrt9a3N7cZjArgdnUKvqu2qelzSQUlHbT+2y31Wq2q5qpYXlyaNxwRwO37WWfeq+l7SmqSVXqYB0IsuZ92XbN8/vX6PpCclfd7zXAAa6nLWfb+kv9ieaOcbw5tV9U6/YwFoqctZ908lHZnDLAB6wjvjgACEDgQgdCAAoQMBCB0IQOhAAEIHAhA6EIDQgQCEDgQgdCAAoQMBCB0IQOhAAEIHAhA6EIDQgQCEDgQgdCAAoQMBCB0IQOhAAO98hmLjndqbkr5qvuPdLUramtPXGgLrG7d5r+9wVS39dGMvoc+T7fWqWh56jr6wvnG7U9bHQ3cgAKEDAfZC6KtDD9Az1jdud8T6Rv8cHcBse+GIDmAGQgcCEDoQgNCBAIQOBPgvQfirzIjTTHUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(out_new[0, 0, :, :].detach().transpose(1, 0), cmap=\"plasma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# test conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c = nn.ConvTranspose2d(\n",
    "    2, 8, kernel_size=(3, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1386, -1.1690, -0.5908])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1386, -1.1690, -0.5908])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b @ c)[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.ConvTranspose2d(\n",
    "    2, 8, kernel_size=(3, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=nn.Linear(32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
