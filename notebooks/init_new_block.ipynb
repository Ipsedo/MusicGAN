{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_block = nn.Sequential(\n",
    "    nn.ConvTranspose2d(\n",
    "        32, 32,\n",
    "        kernel_size=(3, 3),\n",
    "        stride=(2, 2),\n",
    "        padding=(1, 1),\n",
    "        output_padding=(1, 1)\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.ConvTranspose2d(\n",
    "        32, 24,\n",
    "        kernel_size=(3, 3),\n",
    "        stride=(1, 1),\n",
    "        padding=(1, 1)\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.ConvTranspose2d(\n",
    "        24, 1,\n",
    "        kernel_size=(1, 1),\n",
    "        stride=(1, 1),\n",
    "        padding=(0, 0)\n",
    "    ),\n",
    "    nn.Tanh()\n",
    ")\n",
    "\n",
    "last_block = nn.Sequential(\n",
    "    nn.ConvTranspose2d(\n",
    "        32, 1,\n",
    "        kernel_size=(1, 1),\n",
    "        stride=(1, 1),\n",
    "        padding=(0, 0)\n",
    "    ),\n",
    "    nn.Tanh(),\n",
    "    nn.Upsample(\n",
    "        scale_factor=2,\n",
    "        mode=\"nearest\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_block[0].weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_block[0].weight[:, :, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with th.no_grad():\n",
    "    new_block[0].weight.zero_()\n",
    "    new_block[0].weight[:, :, 1, 1] = th.eye(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_block[0].weight[:, :, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "last_block[0].weight[:, :, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code Thierry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun May 15 14:11:27 2022\n",
    "\n",
    "@author: thierry\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def multiple(A,p):\n",
    "    \n",
    "    n,q = A.shape\n",
    "    if min(n,q)>p:\n",
    "        print('On fait une ACP...')\n",
    "        \n",
    "    U,D,V = np.linalg.svd(A, full_matrices=True)\n",
    "\n",
    "    DD = np.zeros(p)\n",
    "    DD[:min([n,p,q])] = np.sqrt(D[:min([n,p,q])])\n",
    "    D1 = np.zeros((n,p))\n",
    "    np.fill_diagonal(D1,DD)\n",
    "    D2 = np.zeros((p,q))  \n",
    "    np.fill_diagonal(D2,DD)\n",
    "    \n",
    "    G = np.random.normal(size=(p,p))\n",
    "    G = G+np.transpose(G)   \n",
    "    E,W = np.linalg.eigh(G)\n",
    "    \n",
    "    B = np.matmul(U,np.matmul(D1,W))\n",
    "    C = np.matmul(np.transpose(W),np.matmul(D2,V))    \n",
    "    \n",
    "    return(B,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_diag(m: th.Tensor, v: th.Tensor) -> th.Tensor:\n",
    "    mask = th.diag(th.ones_like(v))\n",
    "    full_mask = th.zeros(*m.size())\n",
    "    start, end = min(full_mask.size()[0], mask.size()[0]), min(full_mask.size()[1], mask.size()[1])\n",
    "    full_mask[:start, :end] = mask[:start, :end]\n",
    "    \n",
    "    diag = th.diag(v)\n",
    "    full_diag = th.zeros(*m.size())\n",
    "    start, end = min(full_diag.size()[0], diag.size()[0]), min(full_diag.size()[1], diag.size()[1])\n",
    "    full_diag[:start, :end] = diag[:start, :end]\n",
    "    \n",
    "    return full_mask * full_diag + (1. - full_mask) * m\n",
    "\n",
    "def decomposition(m: th.Tensor, p: int) -> Tuple[th.Tensor, th.Tensor]:\n",
    "    n, q = m.size()[-2:]\n",
    "    \n",
    "    u, d, v = th.linalg.svd(m, full_matrices=True)\n",
    "    \n",
    "    d_diag = th.zeros(p)\n",
    "    d_diag[:min(n, p, q)] = th.sqrt(d[:min(n, p, q)])\n",
    "    \n",
    "    d1 = th.zeros(n, p)\n",
    "    d1 = fill_diag(d1, d_diag)\n",
    "    \n",
    "    d2 = th.zeros(p, q)\n",
    "    d2 = fill_diag(d2, d_diag)\n",
    "    \n",
    "    g = th.randn(p, p)\n",
    "    g = g + g.transpose(1, 0)\n",
    "    e, w = th.linalg.eigh(g)\n",
    "    \n",
    "    b = u @ (d1 @ w)\n",
    "    c = w.transpose(1, 0) @ (d2 @ v)\n",
    "    \n",
    "    return b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = th.randn(64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1, m_2 = decomposition(m, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round(t: th.Tensor, decimals=0) -> th.Tensor:\n",
    "    return (t * 10 ** decimals).round() / (10 ** decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True, False],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(m_1 @ m_2, decimals=5) == round(m, decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu113'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.ConvTranspose2d(\n",
    "    32, 32,\n",
    "    kernel_size=(3, 3),\n",
    "    stride=(2, 2),\n",
    "    padding=(1, 1),\n",
    "    output_padding=(1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.zeros_(conv.weight)\n",
    "nn.init.zeros_(conv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight.data[:, :, 1:, 1:] = (\n",
    "    th.eye(32)[:, :, None, None]\n",
    "    .repeat(1, 1, 2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data[:, :, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = th.ones(1, 32, 2, 2)\n",
    "v[:, :, 0, 0] = 1\n",
    "v[:, :, 1, 0] = 2\n",
    "v[:, :, 0, 1] = 3\n",
    "v[:, :, 1, 1] = 4\n",
    "o = conv(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]],\n",
       "\n",
       "         [[1., 1., 3., 3.],\n",
       "          [1., 1., 3., 3.],\n",
       "          [2., 2., 4., 4.],\n",
       "          [2., 2., 4., 4.]]]], grad_fn=<SlowConvTranspose2DBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(\n",
    "    32, 32,\n",
    "    kernel_size=(3, 3),\n",
    "    stride=(2, 2),\n",
    "    padding=(1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.zeros_(conv.weight)\n",
    "nn.init.zeros_(conv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conv.weight.data[:, :, 1:, 1:] = (\n",
    "    th.eye(32)[:, :, None, None]\n",
    "    .repeat(1, 1, 2, 2) / 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "o = conv(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]],\n",
       "\n",
       "         [[1., 3.],\n",
       "          [2., 4.]]]], grad_fn=<SlowConv2DBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_gan.networks import matrix_multiple\n",
    "\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = th.randn(32, 2)\n",
    "b, c = matrix_multiple(a, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [False,  True],\n",
       "        [ True, False],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(b @ c, decimals=5) == round(a, decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(b @ c)[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(b @ c)[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# test conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c = nn.ConvTranspose2d(\n",
    "    2, 8, kernel_size=(3, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1386, -1.1690, -0.5908])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1386, -1.1690, -0.5908])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b @ c)[round(b @ c, decimals=5) != round(a, decimals=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.ConvTranspose2d(\n",
    "    2, 8, kernel_size=(3, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=nn.Linear(32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
